{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Importing the libraries and MNIST Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddf7b5e9e7a43537"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((array([[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         ...,\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n (array([[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         ...,\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "data = mnist.load_data()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T04:10:45.179853Z",
     "start_time": "2024-06-12T04:10:44.793458Z"
    }
   },
   "id": "16b44c79280cd5d2",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tuple"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T04:10:45.190693Z",
     "start_time": "2024-06-12T04:10:45.183176Z"
    }
   },
   "id": "ea0d9d8e37ee9f15",
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fefaeeb31ce1bfa9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (60000, 28, 28)\n",
      "y_train shape:  (60000,)\n",
      "X_test shape:  (10000, 28, 28)\n",
      "y_test shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = data\n",
    "\n",
    "# print the shape of all the data sets with description\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T04:10:45.214375Z",
     "start_time": "2024-06-12T04:10:45.191844Z"
    }
   },
   "id": "1449114b7c62580a",
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "X_train = X_train.reshape((X_train.shape[0], 28*28)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28*28)).astype('float32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T04:10:45.332678Z",
     "start_time": "2024-06-12T04:10:45.216767Z"
    }
   },
   "id": "c5705a02096ce337",
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Normalize the pixel values from a scale of 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T04:10:45.455761Z",
     "start_time": "2024-06-12T04:10:45.335019Z"
    }
   },
   "id": "eeb4cbe716eeba14",
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Build the model without Deep Learning Libraries (Traditional)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a1822e7caabd1e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# Topology: 784 -> 256 -> 10\n",
    "# Activation Function: Sigmoid -> Softmax\n",
    "# Loss Function: Categorical Crossentropy\n",
    "# Optimizer: Stochastic Gradient Descent\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_shifted = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_shifted / np.sum(exp_shifted, axis=1, keepdims=True)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    L_sum = np.sum(np.multiply(y_true, np.log(y_pred)))\n",
    "    m = y_true.shape[0]\n",
    "    L = -(1/m) * L_sum\n",
    "    return L\n",
    "\n",
    "def softmax_cross_entropy_loss(y_true, y_pred):\n",
    "    loss = -np.sum(y_true * np.log(y_pred + 1e-15))\n",
    "    return loss\n",
    "\n",
    "def BenchmarkModel(X_train, y_train, X_test, y_test):\n",
    "    # Initialize the weights and biases\n",
    "    input_dim = X_train.shape[1]\n",
    "    hidden_dim = 256\n",
    "    output_dim = 10\n",
    "    lr = 0.1\n",
    "    epochs = 3\n",
    "\n",
    "    W1 = np.random.randn(input_dim, hidden_dim)\n",
    "    b1 = np.zeros((1, hidden_dim))\n",
    "    W2 = np.random.randn(hidden_dim, output_dim)\n",
    "    b2 = np.zeros((1, output_dim))\n",
    "\n",
    "    # Training the model\n",
    "    for i in range(epochs):\n",
    "        # Forward Propagation\n",
    "        z1 = np.dot(X_train, W1) + b1\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = np.dot(a1, W2) + b2\n",
    "        a2 = softmax(z2)\n",
    "\n",
    "        # Loss Calculation\n",
    "        loss = softmax_cross_entropy_loss(y_train, a2)\n",
    "        print(\"Epoch \", i, \" Loss: \", loss)\n",
    "\n",
    "        # Backward Propagation\n",
    "        dl_a2 = a2 - y_train\n",
    "        dl_z2 = np.dot(dl_a2, W2.T)\n",
    "        dl_W2 = np.dot(a1.T, dl_a2)\n",
    "        dl_b2 = np.sum(dl_a2, axis=0, keepdims=True)\n",
    "        dl_a1 = np.dot(dl_a2, W2.T)\n",
    "        dl_z1 = dl_a1 * sigmoid_derivative(a1)\n",
    "        dl_W1 = np.dot(X_train.T, dl_z1)\n",
    "        dl_b1 = np.sum(dl_z1, axis=0, keepdims=True)\n",
    "\n",
    "        # Update the weights and biases\n",
    "        W1 = W1 - lr * dl_W1\n",
    "        b1 = b1 - lr * dl_b1\n",
    "        W2 = W2 - lr * dl_W2\n",
    "        b2 = b2 - lr * dl_b2\n",
    "\n",
    "    # Testing the model\n",
    "    z1 = np.dot(X_test, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = softmax(z2)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    predictions = np.argmax(a2, axis=1)\n",
    "    labels = np.argmax(y_test, axis=1)\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def evaluate(X_test, y_test, W1, b1, W2, b2):\n",
    "    # Testing the model\n",
    "    z1 = np.dot(X_test, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = softmax(z2)\n",
    "\n",
    "    # Calculate the accuracy, precision, recall, and f1 score\n",
    "    predictions = np.argmax(a2, axis=1)\n",
    "    labels = np.argmax(y_test, axis=1)\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    precision = np.sum(predictions & labels) / np.sum(predictions)\n",
    "    recall = np.sum(predictions & labels) / np.sum(labels)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "    n_values = np.max(y) + 1\n",
    "    return np.eye(n_values)[y]\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T04:10:45.492313Z",
     "start_time": "2024-06-12T04:10:45.457891Z"
    }
   },
   "id": "8812b3e38190fb38",
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Train the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac73635af6902744"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  Loss:  1031011.2059609923\n",
      "Epoch  1  Loss:  1839466.1532401552\n",
      "Epoch  2  Loss:  1855941.1495805276\n",
      "Accuracy:  0.101\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding the labels\n",
    "y_train = one_hot_encoding(y_train)\n",
    "y_test = one_hot_encoding(y_test)  # Ensure y_test is also one-hot encoded\n",
    "\n",
    "# Train the model\n",
    "W1, b1, W2, b2 = BenchmarkModel(X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T04:10:53.622668Z",
     "start_time": "2024-06-12T04:10:45.494730Z"
    }
   },
   "id": "a8bdb569bda6debf",
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Evaluate the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71219fc60e970987"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.101\n",
      "Precision:  0.43766666666666665\n",
      "Recall:  0.2954944411936805\n",
      "F1 Score:  0.3527957653760378\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy, precision, recall, f1 = evaluate(X_test, y_test, W1, b1, W2, b2)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T04:10:53.954936Z",
     "start_time": "2024-06-12T04:10:53.623742Z"
    }
   },
   "id": "648269ca2e5f9bc1",
   "execution_count": 115
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
